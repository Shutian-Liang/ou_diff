1.5
+------------------------------------------+------------+
|                 Modules                  | Parameters |
+------------------------------------------+------------+
|          model.init_conv.weight          |    4704    |
|           model.init_conv.bias           |     32     |
|         model.time_mlp.1.weight          |    4096    |
|          model.time_mlp.1.bias           |    128     |
|         model.time_mlp.3.weight          |   16384    |
|          model.time_mlp.3.bias           |    128     |
|       model.downs.0.0.mlp.1.weight       |    8192    |
|        model.downs.0.0.mlp.1.bias        |     64     |
|    model.downs.0.0.block1.proj.weight    |    9216    |
|     model.downs.0.0.block1.proj.bias     |     32     |
|      model.downs.0.0.block1.norm.g       |     32     |
|    model.downs.0.0.block2.proj.weight    |    9216    |
|     model.downs.0.0.block2.proj.bias     |     32     |
|      model.downs.0.0.block2.norm.g       |     32     |
|       model.downs.0.1.mlp.1.weight       |    8192    |
|        model.downs.0.1.mlp.1.bias        |     64     |
|    model.downs.0.1.block1.proj.weight    |    9216    |
|     model.downs.0.1.block1.proj.bias     |     32     |
|      model.downs.0.1.block1.norm.g       |     32     |
|    model.downs.0.1.block2.proj.weight    |    9216    |
|     model.downs.0.1.block2.proj.bias     |     32     |
|      model.downs.0.1.block2.norm.g       |     32     |
|          model.downs.0.2.mem_kv          |    1024    |
|          model.downs.0.2.norm.g          |     32     |
|      model.downs.0.2.to_qkv.weight       |   12288    |
|     model.downs.0.2.to_out.0.weight      |    4096    |
|      model.downs.0.2.to_out.0.bias       |     32     |
|        model.downs.0.2.to_out.1.g        |     32     |
|         model.downs.0.3.1.weight         |    4096    |
|          model.downs.0.3.1.bias          |     32     |
|       model.downs.1.0.mlp.1.weight       |    8192    |
|        model.downs.1.0.mlp.1.bias        |     64     |
|    model.downs.1.0.block1.proj.weight    |    9216    |
|     model.downs.1.0.block1.proj.bias     |     32     |
|      model.downs.1.0.block1.norm.g       |     32     |
|    model.downs.1.0.block2.proj.weight    |    9216    |
|     model.downs.1.0.block2.proj.bias     |     32     |
|      model.downs.1.0.block2.norm.g       |     32     |
|       model.downs.1.1.mlp.1.weight       |    8192    |
|        model.downs.1.1.mlp.1.bias        |     64     |
|    model.downs.1.1.block1.proj.weight    |    9216    |
|     model.downs.1.1.block1.proj.bias     |     32     |
|      model.downs.1.1.block1.norm.g       |     32     |
|    model.downs.1.1.block2.proj.weight    |    9216    |
|     model.downs.1.1.block2.proj.bias     |     32     |
|      model.downs.1.1.block2.norm.g       |     32     |
|          model.downs.1.2.mem_kv          |    1024    |
|          model.downs.1.2.norm.g          |     32     |
|      model.downs.1.2.to_qkv.weight       |   12288    |
|     model.downs.1.2.to_out.0.weight      |    4096    |
|      model.downs.1.2.to_out.0.bias       |     32     |
|        model.downs.1.2.to_out.1.g        |     32     |
|         model.downs.1.3.1.weight         |    8192    |
|          model.downs.1.3.1.bias          |     64     |
|       model.downs.2.0.mlp.1.weight       |   16384    |
|        model.downs.2.0.mlp.1.bias        |    128     |
|    model.downs.2.0.block1.proj.weight    |   36864    |
|     model.downs.2.0.block1.proj.bias     |     64     |
|      model.downs.2.0.block1.norm.g       |     64     |
|    model.downs.2.0.block2.proj.weight    |   36864    |
|     model.downs.2.0.block2.proj.bias     |     64     |
|      model.downs.2.0.block2.norm.g       |     64     |
|       model.downs.2.1.mlp.1.weight       |   16384    |
|        model.downs.2.1.mlp.1.bias        |    128     |
|    model.downs.2.1.block1.proj.weight    |   36864    |
|     model.downs.2.1.block1.proj.bias     |     64     |
|      model.downs.2.1.block1.norm.g       |     64     |
|    model.downs.2.1.block2.proj.weight    |   36864    |
|     model.downs.2.1.block2.proj.bias     |     64     |
|      model.downs.2.1.block2.norm.g       |     64     |
|          model.downs.2.2.mem_kv          |    1024    |
|          model.downs.2.2.norm.g          |     64     |
|      model.downs.2.2.to_qkv.weight       |   24576    |
|     model.downs.2.2.to_out.0.weight      |    8192    |
|      model.downs.2.2.to_out.0.bias       |     64     |
|        model.downs.2.2.to_out.1.g        |     64     |
|         model.downs.2.3.1.weight         |   32768    |
|          model.downs.2.3.1.bias          |    128     |
|       model.downs.3.0.mlp.1.weight       |   32768    |
|        model.downs.3.0.mlp.1.bias        |    256     |
|    model.downs.3.0.block1.proj.weight    |   147456   |
|     model.downs.3.0.block1.proj.bias     |    128     |
|      model.downs.3.0.block1.norm.g       |    128     |
|    model.downs.3.0.block2.proj.weight    |   147456   |
|     model.downs.3.0.block2.proj.bias     |    128     |
|      model.downs.3.0.block2.norm.g       |    128     |
|       model.downs.3.1.mlp.1.weight       |   32768    |
|        model.downs.3.1.mlp.1.bias        |    256     |
|    model.downs.3.1.block1.proj.weight    |   147456   |
|     model.downs.3.1.block1.proj.bias     |    128     |
|      model.downs.3.1.block1.norm.g       |    128     |
|    model.downs.3.1.block2.proj.weight    |   147456   |
|     model.downs.3.1.block2.proj.bias     |    128     |
|      model.downs.3.1.block2.norm.g       |    128     |
|          model.downs.3.2.mem_kv          |    1024    |
|          model.downs.3.2.norm.g          |    128     |
|      model.downs.3.2.to_qkv.weight       |   49152    |
|      model.downs.3.2.to_out.weight       |   16384    |
|       model.downs.3.2.to_out.bias        |    128     |
|          model.downs.3.3.weight          |   294912   |
|           model.downs.3.3.bias           |    256     |
|        model.ups.0.0.mlp.1.weight        |   65536    |
|         model.ups.0.0.mlp.1.bias         |    512     |
|     model.ups.0.0.block1.proj.weight     |   884736   |
|      model.ups.0.0.block1.proj.bias      |    256     |
|       model.ups.0.0.block1.norm.g        |    256     |
|     model.ups.0.0.block2.proj.weight     |   589824   |
|      model.ups.0.0.block2.proj.bias      |    256     |
|       model.ups.0.0.block2.norm.g        |    256     |
|      model.ups.0.0.res_conv.weight       |   98304    |
|       model.ups.0.0.res_conv.bias        |    256     |
|        model.ups.0.1.mlp.1.weight        |   65536    |
|         model.ups.0.1.mlp.1.bias         |    512     |
|     model.ups.0.1.block1.proj.weight     |   884736   |
|      model.ups.0.1.block1.proj.bias      |    256     |
|       model.ups.0.1.block1.norm.g        |    256     |
|     model.ups.0.1.block2.proj.weight     |   589824   |
|      model.ups.0.1.block2.proj.bias      |    256     |
|       model.ups.0.1.block2.norm.g        |    256     |
|      model.ups.0.1.res_conv.weight       |   98304    |
|       model.ups.0.1.res_conv.bias        |    256     |
|           model.ups.0.2.mem_kv           |    1024    |
|           model.ups.0.2.norm.g           |    256     |
|       model.ups.0.2.to_qkv.weight        |   98304    |
|       model.ups.0.2.to_out.weight        |   32768    |
|        model.ups.0.2.to_out.bias         |    256     |
|          model.ups.0.3.1.weight          |   294912   |
|           model.ups.0.3.1.bias           |    128     |
|        model.ups.1.0.mlp.1.weight        |   32768    |
|         model.ups.1.0.mlp.1.bias         |    256     |
|     model.ups.1.0.block1.proj.weight     |   221184   |
|      model.ups.1.0.block1.proj.bias      |    128     |
|       model.ups.1.0.block1.norm.g        |    128     |
|     model.ups.1.0.block2.proj.weight     |   147456   |
|      model.ups.1.0.block2.proj.bias      |    128     |
|       model.ups.1.0.block2.norm.g        |    128     |
|      model.ups.1.0.res_conv.weight       |   24576    |
|       model.ups.1.0.res_conv.bias        |    128     |
|        model.ups.1.1.mlp.1.weight        |   32768    |
|         model.ups.1.1.mlp.1.bias         |    256     |
|     model.ups.1.1.block1.proj.weight     |   221184   |
|      model.ups.1.1.block1.proj.bias      |    128     |
|       model.ups.1.1.block1.norm.g        |    128     |
|     model.ups.1.1.block2.proj.weight     |   147456   |
|      model.ups.1.1.block2.proj.bias      |    128     |
|       model.ups.1.1.block2.norm.g        |    128     |
|      model.ups.1.1.res_conv.weight       |   24576    |
|       model.ups.1.1.res_conv.bias        |    128     |
|           model.ups.1.2.mem_kv           |    1024    |
|           model.ups.1.2.norm.g           |    128     |
|       model.ups.1.2.to_qkv.weight        |   49152    |
|      model.ups.1.2.to_out.0.weight       |   16384    |
|       model.ups.1.2.to_out.0.bias        |    128     |
|         model.ups.1.2.to_out.1.g         |    128     |
|          model.ups.1.3.1.weight          |   73728    |
|           model.ups.1.3.1.bias           |     64     |
|        model.ups.2.0.mlp.1.weight        |   16384    |
|         model.ups.2.0.mlp.1.bias         |    128     |
|     model.ups.2.0.block1.proj.weight     |   55296    |
|      model.ups.2.0.block1.proj.bias      |     64     |
|       model.ups.2.0.block1.norm.g        |     64     |
|     model.ups.2.0.block2.proj.weight     |   36864    |
|      model.ups.2.0.block2.proj.bias      |     64     |
|       model.ups.2.0.block2.norm.g        |     64     |
|      model.ups.2.0.res_conv.weight       |    6144    |
|       model.ups.2.0.res_conv.bias        |     64     |
|        model.ups.2.1.mlp.1.weight        |   16384    |
|         model.ups.2.1.mlp.1.bias         |    128     |
|     model.ups.2.1.block1.proj.weight     |   55296    |
|      model.ups.2.1.block1.proj.bias      |     64     |
|       model.ups.2.1.block1.norm.g        |     64     |
|     model.ups.2.1.block2.proj.weight     |   36864    |
|      model.ups.2.1.block2.proj.bias      |     64     |
|       model.ups.2.1.block2.norm.g        |     64     |
|      model.ups.2.1.res_conv.weight       |    6144    |
|       model.ups.2.1.res_conv.bias        |     64     |
|           model.ups.2.2.mem_kv           |    1024    |
|           model.ups.2.2.norm.g           |     64     |
|       model.ups.2.2.to_qkv.weight        |   24576    |
|      model.ups.2.2.to_out.0.weight       |    8192    |
|       model.ups.2.2.to_out.0.bias        |     64     |
|         model.ups.2.2.to_out.1.g         |     64     |
|          model.ups.2.3.1.weight          |   18432    |
|           model.ups.2.3.1.bias           |     32     |
|        model.ups.3.0.mlp.1.weight        |    8192    |
|         model.ups.3.0.mlp.1.bias         |     64     |
|     model.ups.3.0.block1.proj.weight     |   18432    |
|      model.ups.3.0.block1.proj.bias      |     32     |
|       model.ups.3.0.block1.norm.g        |     32     |
|     model.ups.3.0.block2.proj.weight     |    9216    |
|      model.ups.3.0.block2.proj.bias      |     32     |
|       model.ups.3.0.block2.norm.g        |     32     |
|      model.ups.3.0.res_conv.weight       |    2048    |
|       model.ups.3.0.res_conv.bias        |     32     |
|        model.ups.3.1.mlp.1.weight        |    8192    |
|         model.ups.3.1.mlp.1.bias         |     64     |
|     model.ups.3.1.block1.proj.weight     |   18432    |
|      model.ups.3.1.block1.proj.bias      |     32     |
|       model.ups.3.1.block1.norm.g        |     32     |
|     model.ups.3.1.block2.proj.weight     |    9216    |
|      model.ups.3.1.block2.proj.bias      |     32     |
|       model.ups.3.1.block2.norm.g        |     32     |
|      model.ups.3.1.res_conv.weight       |    2048    |
|       model.ups.3.1.res_conv.bias        |     32     |
|           model.ups.3.2.mem_kv           |    1024    |
|           model.ups.3.2.norm.g           |     32     |
|       model.ups.3.2.to_qkv.weight        |   12288    |
|      model.ups.3.2.to_out.0.weight       |    4096    |
|       model.ups.3.2.to_out.0.bias        |     32     |
|         model.ups.3.2.to_out.1.g         |     32     |
|           model.ups.3.3.weight           |    9216    |
|            model.ups.3.3.bias            |     32     |
|      model.mid_block1.mlp.1.weight       |   65536    |
|       model.mid_block1.mlp.1.bias        |    512     |
|   model.mid_block1.block1.proj.weight    |   589824   |
|    model.mid_block1.block1.proj.bias     |    256     |
|      model.mid_block1.block1.norm.g      |    256     |
|   model.mid_block1.block2.proj.weight    |   589824   |
|    model.mid_block1.block2.proj.bias     |    256     |
|      model.mid_block1.block2.norm.g      |    256     |
|          model.mid_attn.mem_kv           |    1024    |
|          model.mid_attn.norm.g           |    256     |
|       model.mid_attn.to_qkv.weight       |   98304    |
|       model.mid_attn.to_out.weight       |   32768    |
|        model.mid_attn.to_out.bias        |    256     |
|      model.mid_block2.mlp.1.weight       |   65536    |
|       model.mid_block2.mlp.1.bias        |    512     |
|   model.mid_block2.block1.proj.weight    |   589824   |
|    model.mid_block2.block1.proj.bias     |    256     |
|      model.mid_block2.block1.norm.g      |    256     |
|   model.mid_block2.block2.proj.weight    |   589824   |
|    model.mid_block2.block2.proj.bias     |    256     |
|      model.mid_block2.block2.norm.g      |    256     |
|    model.final_res_block.mlp.1.weight    |    8192    |
|     model.final_res_block.mlp.1.bias     |     64     |
| model.final_res_block.block1.proj.weight |   18432    |
|  model.final_res_block.block1.proj.bias  |     32     |
|   model.final_res_block.block1.norm.g    |     32     |
| model.final_res_block.block2.proj.weight |    9216    |
|  model.final_res_block.block2.proj.bias  |     32     |
|   model.final_res_block.block2.norm.g    |     32     |
|  model.final_res_block.res_conv.weight   |    2048    |
|   model.final_res_block.res_conv.bias    |     32     |
|         model.final_conv.weight          |     96     |
|          model.final_conv.bias           |     3      |
+------------------------------------------+------------+
Total Trainable Params: 9199363
Epoch 0, Step [0/1563], Loss: 1.0798
Epoch 0, Step [100/1563], Loss: 0.3670
Epoch 0, Step [200/1563], Loss: 0.2618
Epoch 0, Step [300/1563], Loss: 0.2345
Epoch 0, Step [400/1563], Loss: 0.1536
Epoch 0, Step [500/1563], Loss: 0.1709
Epoch 0, Step [600/1563], Loss: 0.1231
Epoch 0, Step [700/1563], Loss: 0.1557
Epoch 0, Step [800/1563], Loss: 0.1682
Epoch 0, Step [900/1563], Loss: 0.1265
Epoch 0, Step [1000/1563], Loss: 0.1772
Epoch 0, Step [1100/1563], Loss: 0.1055
